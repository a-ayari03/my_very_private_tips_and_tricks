{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.8-cp310-cp310-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_core-0.3.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.130-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.13.1-cp310-cp310-win_amd64.whl.metadata (52 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp310-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\alexa\\desktop\\fr\\project\\my_very_private_tips_and_tricks\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 46.4 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.8-cp310-cp310-win_amd64.whl (380 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.8-py3-none-any.whl (400 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.130-py3-none-any.whl (294 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 15.8/15.8 MB 83.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 114.0 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl (100 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "Downloading greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.7-cp310-none-win_amd64.whl (137 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.13.1-cp310-cp310-win_amd64.whl (111 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tenacity, PyYAML, orjson, numpy, multidict, jsonpointer, greenlet, frozenlist, charset-normalizer, attrs, async-timeout, aiohappyeyeballs, yarl, SQLAlchemy, requests, jsonpatch, aiosignal, requests-toolbelt, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 charset-normalizer-3.3.2 frozenlist-1.4.1 greenlet-3.1.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-core-0.3.8 langchain-text-splitters-0.3.0 langsmith-0.1.130 multidict-6.1.0 numpy-1.26.4 orjson-3.10.7 requests-2.32.3 requests-toolbelt-1.0.0 tenacity-8.5.0 yarl-1.13.1\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain\n",
    "! pip install langchain_community\n",
    "! pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents: [0, 1, 2, 3, 4, 5, 6, 8, 9, 10]\n",
      "Explanation: These documents address various aspects of climate change, including its primary factors (greenhouse gas emissions, deforestation), the interaction with economic policies (economic globalization, carbon pricing), and proposed solutions (renewable energy technologies, climate finance mechanisms) that impact developing nations. They provide substantial information relevant to the user's questions.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "class DocumentRelevance(BaseModel):\n",
    "    \"\"\"Evaluate the relevance of multiple documents to a question.\"\"\"\n",
    "    relevant_indices: List[int] = Field(..., description=\"Indices of documents that are relevant to the question\")\n",
    "    explanation: str = Field(..., description=\"Brief explanation of why these documents were selected as relevant\")\n",
    "\n",
    "# Define the prompt to grade documents\n",
    "grade_documents_prompt = \"\"\"\n",
    "You are a grader tasked with assessing the relevance of retrieved documents to a set of user questions.\n",
    "Instructions:\n",
    "1. Carefully examine each user question.\n",
    "2. Analyze the content of each provided document.\n",
    "3. Evaluate if each document contains keywords or semantic meaning related to AT LEAST ONE of the user questions.\n",
    "4. The evaluation should not be overly strict. The goal is to filter out erroneous retrievals.\n",
    "5. For each document, give a binary score 'yes' or 'no' to indicate whether it is relevant to AT LEAST ONE of the questions.\n",
    "6. Consider linguistic variations and possible synonyms between the questions and the documents.\n",
    "7. Take into account the overall context of each document, not just word-for-word matches.\n",
    "8. If a document provides partial or indirect information related to a question, consider it relevant. Evaluate if the partial information is substantial enough to be useful to the user.\n",
    "9. Pay attention to temporal aspects - a document might be relevant even if it doesn't exactly match the time frame of the question. Consider if dated information could still be relevant or provide useful historical context.\n",
    "10. Consider cultural and contextual nuances that might affect the relevance of the documents to the questions.\n",
    "11. If multiple questions are asked, a document is considered relevant if it substantially answers at least one of the questions.\n",
    "12. If a document directly contradicts the premise of a question but provides correct and relevant information, consider it relevant.\n",
    "13. While assessing reliability is not the primary focus, note any information that is clearly false or misleading.\n",
    "14. For long documents, focus on the sections most relevant to the question.\n",
    "15. For complex questions requiring synthesis, evaluate if a document provides key elements to construct an answer, even if it doesn't directly answer the question.\n",
    "Note: A document is considered relevant if it addresses at least one of the questions, even if it doesn't address all of them.\n",
    "\n",
    "User questions: {question}\n",
    "Documents:\n",
    "{documents}\n",
    "Relevant document indices:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the language model\n",
    "OPENAI_API_KEY = \"sx-xxx\"\n",
    "llm_grade_docs = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "structured_llm_grader = llm_grade_docs.with_structured_output(DocumentRelevance)\n",
    "\n",
    "# Create the grading prompt\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", grade_documents_prompt)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the retrieval grader\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# Example usage\n",
    "question = \"What are the primary factors contributing to climate change, and how do they interact with global economic policies? Additionally, what are some proposed solutions and their potential impacts on developing nations?\"\n",
    "\n",
    "documents = [\n",
    "    \"The Intergovernmental Panel on Climate Change (IPCC) identifies greenhouse gas emissions, primarily CO2 from fossil fuel combustion, as the main driver of climate change. These emissions are closely tied to economic activities, particularly in energy-intensive industries.\",\n",
    "    \"Economic globalization has led to increased industrial production in developing nations, often with less stringent environmental regulations. This shift in manufacturing has contributed to higher global emissions while also driving economic growth in these countries.\",\n",
    "    \"Deforestation, particularly in tropical regions, contributes significantly to climate change by reducing the Earth's capacity to absorb CO2. Many developing nations face pressure to clear forests for agriculture or resource extraction to support their economies.\",\n",
    "    \"The Paris Agreement aims to limit global temperature increase to well below 2Â°C above pre-industrial levels. It requires nations to set their own emissions reduction targets, considering their economic circumstances.\",\n",
    "    \"Carbon pricing mechanisms, such as cap-and-trade systems or carbon taxes, are proposed as market-based solutions to reduce emissions. However, implementing these in developing nations can be challenging due to concerns about economic competitiveness.\",\n",
    "    \"Renewable energy technologies, including solar and wind power, are becoming increasingly cost-competitive with fossil fuels. This trend presents opportunities for developing nations to leapfrog traditional fossil fuel infrastructure.\",\n",
    "    \"The history of ancient Rome is fascinating, spanning over a thousand years. From its founding as a small village to becoming a vast empire, Rome's influence on Western civilization cannot be overstated.\", # not relevant\n",
    "    \"Climate change disproportionately affects developing nations, exacerbating existing socio-economic challenges such as food security, water scarcity, and vulnerability to extreme weather events.\",\n",
    "    \"The concept of 'just transition' emphasizes the need to ensure that the shift to a low-carbon economy doesn't unfairly burden vulnerable communities or nations. This includes providing support for workers and communities dependent on fossil fuel industries.\",\n",
    "    \"Artificial Intelligence is rapidly evolving, with applications ranging from natural language processing to autonomous vehicles. As AI becomes more sophisticated, it raises important ethical and societal questions.\",\n",
    "    \"International climate finance mechanisms aim to support developing nations in adopting clean technologies and adapting to climate change impacts. However, the scale of funding required remains a significant challenge.\",\n",
    "    \"The global coffee industry faces numerous challenges, including price volatility, changing consumer preferences, and the impact of climate change on coffee-growing regions. Sustainability initiatives are becoming increasingly important in this sector.\" # not relevant\n",
    "]\n",
    "\n",
    "result = retrieval_grader.invoke({\"question\": question, \"documents\": documents})\n",
    "print(f\"Relevant documents: {result.relevant_indices}\")\n",
    "print(f\"Explanation: {result.explanation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
